Dask client initialized
Subsampling applied: keeping 1 every 5 rows
Rows before: 11,279,275
Rows after:  2,255,855
Retained:    20.00%
Dataset 'acc_phone' loaded with 10 partitions
Training time-series model: cnn
âœ… Time-series windows extracted: 8796
/Volumes/APFS_Bry_SSD/opt/anaconda3/envs/TFM/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                         â”ƒ Output Shape                â”ƒ         Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ conv1d (Conv1D)                      â”‚ (None, 512, 64)             â”‚           1,024 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling1d (MaxPooling1D)         â”‚ (None, 256, 64)             â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_1 (Conv1D)                    â”‚ (None, 256, 64)             â”‚          20,544 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling1d_1 (MaxPooling1D)       â”‚ (None, 128, 64)             â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten (Flatten)                    â”‚ (None, 8192)                â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                        â”‚ (None, 128)                 â”‚       1,048,704 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)                    â”‚ (None, 128)                 â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                      â”‚ (None, 6)                   â”‚             774 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 1,071,046 (4.09 MB)
 Trainable params: 1,071,046 (4.09 MB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/40
44/44 - 2s - 36ms/step - accuracy: 0.3680 - loss: 2.2222 - val_accuracy: 0.5487 - val_loss: 1.1769
Epoch 2/40
44/44 - 1s - 27ms/step - accuracy: 0.5407 - loss: 1.1464 - val_accuracy: 0.6120 - val_loss: 0.9958
Epoch 3/40
44/44 - 1s - 28ms/step - accuracy: 0.6261 - loss: 0.9550 - val_accuracy: 0.6867 - val_loss: 0.8641
Epoch 4/40
44/44 - 1s - 29ms/step - accuracy: 0.6849 - loss: 0.8118 - val_accuracy: 0.6640 - val_loss: 0.8165
Epoch 5/40
44/44 - 1s - 30ms/step - accuracy: 0.7329 - loss: 0.7013 - val_accuracy: 0.7468 - val_loss: 0.6695
Epoch 6/40
44/44 - 1s - 29ms/step - accuracy: 0.7746 - loss: 0.6084 - val_accuracy: 0.7305 - val_loss: 0.7091
Epoch 7/40
44/44 - 1s - 30ms/step - accuracy: 0.7833 - loss: 0.5691 - val_accuracy: 0.7711 - val_loss: 0.6131
Epoch 8/40
44/44 - 1s - 29ms/step - accuracy: 0.8231 - loss: 0.4743 - val_accuracy: 0.8084 - val_loss: 0.5908
Epoch 9/40
44/44 - 1s - 29ms/step - accuracy: 0.8563 - loss: 0.4110 - val_accuracy: 0.7971 - val_loss: 0.5889
Epoch 10/40
44/44 - 1s - 29ms/step - accuracy: 0.8408 - loss: 0.4383 - val_accuracy: 0.7646 - val_loss: 0.6807
Epoch 11/40
44/44 - 1s - 30ms/step - accuracy: 0.8794 - loss: 0.3420 - val_accuracy: 0.8133 - val_loss: 0.5901
Epoch 12/40
44/44 - 1s - 30ms/step - accuracy: 0.8930 - loss: 0.2977 - val_accuracy: 0.7987 - val_loss: 0.6001
Epoch 13/40
44/44 - 1s - 29ms/step - accuracy: 0.9164 - loss: 0.2392 - val_accuracy: 0.8231 - val_loss: 0.5889
Epoch 14/40
44/44 - 1s - 29ms/step - accuracy: 0.9182 - loss: 0.2300 - val_accuracy: 0.8166 - val_loss: 0.6367
Epoch 15/40
44/44 - 1s - 30ms/step - accuracy: 0.9365 - loss: 0.1949 - val_accuracy: 0.8166 - val_loss: 0.6212
Epoch 16/40
44/44 - 1s - 29ms/step - accuracy: 0.9359 - loss: 0.1946 - val_accuracy: 0.7906 - val_loss: 0.7058
Epoch 17/40
44/44 - 1s - 29ms/step - accuracy: 0.9525 - loss: 0.1498 - val_accuracy: 0.8036 - val_loss: 0.6914
Epoch 18/40
44/44 - 1s - 30ms/step - accuracy: 0.9515 - loss: 0.1459 - val_accuracy: 0.8117 - val_loss: 0.6866
Epoch 19/40
44/44 - 1s - 30ms/step - accuracy: 0.9533 - loss: 0.1383 - val_accuracy: 0.8166 - val_loss: 0.7160
Epoch 20/40
44/44 - 1s - 30ms/step - accuracy: 0.9663 - loss: 0.1108 - val_accuracy: 0.8003 - val_loss: 0.7618
Epoch 21/40
44/44 - 1s - 30ms/step - accuracy: 0.9681 - loss: 0.1044 - val_accuracy: 0.8149 - val_loss: 0.7668
Epoch 22/40
44/44 - 1s - 30ms/step - accuracy: 0.9769 - loss: 0.0789 - val_accuracy: 0.8084 - val_loss: 0.7683
Epoch 23/40
44/44 - 1s - 30ms/step - accuracy: 0.9718 - loss: 0.0903 - val_accuracy: 0.8036 - val_loss: 0.7688
Epoch 24/40
44/44 - 1s - 30ms/step - accuracy: 0.9731 - loss: 0.0842 - val_accuracy: 0.8231 - val_loss: 0.7528
Epoch 25/40
44/44 - 1s - 30ms/step - accuracy: 0.9774 - loss: 0.0702 - val_accuracy: 0.8068 - val_loss: 0.7767
Epoch 26/40
44/44 - 1s - 30ms/step - accuracy: 0.9798 - loss: 0.0689 - val_accuracy: 0.8166 - val_loss: 0.7721
Epoch 27/40
44/44 - 1s - 30ms/step - accuracy: 0.9821 - loss: 0.0558 - val_accuracy: 0.8101 - val_loss: 0.8330
Epoch 28/40
44/44 - 1s - 30ms/step - accuracy: 0.9830 - loss: 0.0620 - val_accuracy: 0.7971 - val_loss: 0.9140
Epoch 29/40
44/44 - 1s - 30ms/step - accuracy: 0.9879 - loss: 0.0484 - val_accuracy: 0.8052 - val_loss: 0.9282
Epoch 30/40
44/44 - 1s - 30ms/step - accuracy: 0.9875 - loss: 0.0447 - val_accuracy: 0.8019 - val_loss: 0.8922
Epoch 31/40
44/44 - 1s - 30ms/step - accuracy: 0.9805 - loss: 0.0591 - val_accuracy: 0.8084 - val_loss: 0.9053
Epoch 32/40
44/44 - 1s - 29ms/step - accuracy: 0.9780 - loss: 0.0703 - val_accuracy: 0.8084 - val_loss: 1.0558
Epoch 33/40
44/44 - 1s - 29ms/step - accuracy: 0.9847 - loss: 0.0517 - val_accuracy: 0.8003 - val_loss: 0.9733
Epoch 34/40
44/44 - 1s - 29ms/step - accuracy: 0.9886 - loss: 0.0402 - val_accuracy: 0.8068 - val_loss: 0.9816
Epoch 35/40
44/44 - 1s - 29ms/step - accuracy: 0.9901 - loss: 0.0324 - val_accuracy: 0.8149 - val_loss: 0.9436
Epoch 36/40
44/44 - 1s - 29ms/step - accuracy: 0.9939 - loss: 0.0297 - val_accuracy: 0.8084 - val_loss: 0.9839
Epoch 37/40
44/44 - 1s - 29ms/step - accuracy: 0.9895 - loss: 0.0362 - val_accuracy: 0.8084 - val_loss: 1.0243
Epoch 38/40
44/44 - 1s - 30ms/step - accuracy: 0.9892 - loss: 0.0384 - val_accuracy: 0.8198 - val_loss: 0.9478
Epoch 39/40
44/44 - 1s - 30ms/step - accuracy: 0.9901 - loss: 0.0346 - val_accuracy: 0.7938 - val_loss: 1.0060
Epoch 40/40
44/44 - 1s - 29ms/step - accuracy: 0.9912 - loss: 0.0295 - val_accuracy: 0.8068 - val_loss: 1.0366

Test accuracy: 0.80181884765625
[1m 1/83[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 26ms/step[1m17/83[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step [1m34/83[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m52/83[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m69/83[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 3ms/step[1m83/83[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 3ms/step[1m83/83[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 3ms/step

Classification report:

              precision    recall  f1-score   support

        bike       0.80      0.72      0.76       408
         sit       0.85      0.93      0.89       481
  stairsdown       0.77      0.69      0.73       343
    stairsup       0.74      0.73      0.74       417
       stand       0.83      0.75      0.79       445
        walk       0.80      0.91      0.85       545

    accuracy                           0.80      2639
   macro avg       0.80      0.79      0.79      2639
weighted avg       0.80      0.80      0.80      2639

Total processing time: 1.25 minutes
