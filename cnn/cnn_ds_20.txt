Dask client initialized
Subsampling applied: keeping 1 every 20 rows
Rows before: 11,279,275
Rows after:  563,964
Retained:    5.00%
Dataset 'acc_phone' loaded with 10 partitions
Training time-series model: cnn
âœ… Time-series windows extracted: 2189
/Volumes/APFS_Bry_SSD/opt/anaconda3/envs/TFM/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                       â”ƒ Output Shape              â”ƒ        Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ conv1d (Conv1D)                    â”‚ (None, 512, 64)           â”‚          1,024 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling1d (MaxPooling1D)       â”‚ (None, 256, 64)           â”‚              0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_1 (Conv1D)                  â”‚ (None, 256, 64)           â”‚         20,544 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling1d_1 (MaxPooling1D)     â”‚ (None, 128, 64)           â”‚              0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten (Flatten)                  â”‚ (None, 8192)              â”‚              0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                      â”‚ (None, 128)               â”‚      1,048,704 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)                  â”‚ (None, 128)               â”‚              0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                    â”‚ (None, 6)                 â”‚            774 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 1,071,046 (4.09 MB)
 Trainable params: 1,071,046 (4.09 MB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/40
11/11 - 1s - 62ms/step - accuracy: 0.2671 - loss: 3.1716 - val_accuracy: 0.3117 - val_loss: 1.6335
Epoch 2/40
11/11 - 0s - 28ms/step - accuracy: 0.3374 - loss: 1.5790 - val_accuracy: 0.3377 - val_loss: 1.4651
Epoch 3/40
11/11 - 0s - 28ms/step - accuracy: 0.3701 - loss: 1.4458 - val_accuracy: 0.4610 - val_loss: 1.3460
Epoch 4/40
11/11 - 0s - 28ms/step - accuracy: 0.4354 - loss: 1.3141 - val_accuracy: 0.4545 - val_loss: 1.2466
Epoch 5/40
11/11 - 0s - 28ms/step - accuracy: 0.5247 - loss: 1.1650 - val_accuracy: 0.5779 - val_loss: 1.1150
Epoch 6/40
11/11 - 0s - 29ms/step - accuracy: 0.6263 - loss: 1.0037 - val_accuracy: 0.6104 - val_loss: 1.0536
Epoch 7/40
11/11 - 0s - 29ms/step - accuracy: 0.6393 - loss: 0.9200 - val_accuracy: 0.5779 - val_loss: 1.0419
Epoch 8/40
11/11 - 0s - 29ms/step - accuracy: 0.6901 - loss: 0.8080 - val_accuracy: 0.6558 - val_loss: 0.9634
Epoch 9/40
11/11 - 0s - 30ms/step - accuracy: 0.7431 - loss: 0.6695 - val_accuracy: 0.5974 - val_loss: 1.0403
Epoch 10/40
11/11 - 0s - 30ms/step - accuracy: 0.7714 - loss: 0.6151 - val_accuracy: 0.6299 - val_loss: 0.9538
Epoch 11/40
11/11 - 0s - 30ms/step - accuracy: 0.7903 - loss: 0.5453 - val_accuracy: 0.6429 - val_loss: 1.0141
Epoch 12/40
11/11 - 0s - 30ms/step - accuracy: 0.8280 - loss: 0.4664 - val_accuracy: 0.5844 - val_loss: 1.0179
Epoch 13/40
11/11 - 0s - 30ms/step - accuracy: 0.8491 - loss: 0.4454 - val_accuracy: 0.6104 - val_loss: 0.9480
Epoch 14/40
11/11 - 0s - 29ms/step - accuracy: 0.8911 - loss: 0.3503 - val_accuracy: 0.6364 - val_loss: 0.9590
Epoch 15/40
11/11 - 0s - 29ms/step - accuracy: 0.9158 - loss: 0.2853 - val_accuracy: 0.6364 - val_loss: 1.0543
Epoch 16/40
11/11 - 0s - 31ms/step - accuracy: 0.9260 - loss: 0.2467 - val_accuracy: 0.6429 - val_loss: 1.0256
Epoch 17/40
11/11 - 0s - 31ms/step - accuracy: 0.9463 - loss: 0.2060 - val_accuracy: 0.6494 - val_loss: 1.0722
Epoch 18/40
11/11 - 0s - 30ms/step - accuracy: 0.9536 - loss: 0.1722 - val_accuracy: 0.6623 - val_loss: 1.0236
Epoch 19/40
11/11 - 0s - 30ms/step - accuracy: 0.9681 - loss: 0.1389 - val_accuracy: 0.6429 - val_loss: 0.9998
Epoch 20/40
11/11 - 0s - 30ms/step - accuracy: 0.9710 - loss: 0.1189 - val_accuracy: 0.6623 - val_loss: 1.2410
Epoch 21/40
11/11 - 0s - 30ms/step - accuracy: 0.9739 - loss: 0.1107 - val_accuracy: 0.6299 - val_loss: 1.1146
Epoch 22/40
11/11 - 0s - 31ms/step - accuracy: 0.9848 - loss: 0.0869 - val_accuracy: 0.6104 - val_loss: 1.1496
Epoch 23/40
11/11 - 0s - 30ms/step - accuracy: 0.9790 - loss: 0.0910 - val_accuracy: 0.6039 - val_loss: 1.4299
Epoch 24/40
11/11 - 0s - 31ms/step - accuracy: 0.9659 - loss: 0.1099 - val_accuracy: 0.6364 - val_loss: 1.1504
Epoch 25/40
11/11 - 0s - 31ms/step - accuracy: 0.9906 - loss: 0.0711 - val_accuracy: 0.6494 - val_loss: 1.1664
Epoch 26/40
11/11 - 0s - 31ms/step - accuracy: 0.9927 - loss: 0.0522 - val_accuracy: 0.6494 - val_loss: 1.2189
Epoch 27/40
11/11 - 0s - 30ms/step - accuracy: 0.9942 - loss: 0.0457 - val_accuracy: 0.6623 - val_loss: 1.2362
Epoch 28/40
11/11 - 0s - 31ms/step - accuracy: 0.9935 - loss: 0.0483 - val_accuracy: 0.6818 - val_loss: 1.2126
Epoch 29/40
11/11 - 0s - 31ms/step - accuracy: 0.9949 - loss: 0.0356 - val_accuracy: 0.6688 - val_loss: 1.2537
Epoch 30/40
11/11 - 0s - 33ms/step - accuracy: 0.9949 - loss: 0.0332 - val_accuracy: 0.6818 - val_loss: 1.3115
Epoch 31/40
11/11 - 0s - 31ms/step - accuracy: 0.9964 - loss: 0.0390 - val_accuracy: 0.6558 - val_loss: 1.3655
Epoch 32/40
11/11 - 0s - 31ms/step - accuracy: 0.9978 - loss: 0.0306 - val_accuracy: 0.6688 - val_loss: 1.2260
Epoch 33/40
11/11 - 0s - 33ms/step - accuracy: 0.9971 - loss: 0.0268 - val_accuracy: 0.6688 - val_loss: 1.3459
Epoch 34/40
11/11 - 0s - 31ms/step - accuracy: 0.9956 - loss: 0.0272 - val_accuracy: 0.6623 - val_loss: 1.2631
Epoch 35/40
11/11 - 0s - 32ms/step - accuracy: 0.9971 - loss: 0.0263 - val_accuracy: 0.6494 - val_loss: 1.4033
Epoch 36/40
11/11 - 0s - 34ms/step - accuracy: 0.9964 - loss: 0.0264 - val_accuracy: 0.6623 - val_loss: 1.4933
Epoch 37/40
11/11 - 0s - 30ms/step - accuracy: 0.9949 - loss: 0.0278 - val_accuracy: 0.6623 - val_loss: 1.3803
Epoch 38/40
11/11 - 0s - 31ms/step - accuracy: 0.9978 - loss: 0.0224 - val_accuracy: 0.6558 - val_loss: 1.5123
Epoch 39/40
11/11 - 0s - 31ms/step - accuracy: 0.9971 - loss: 0.0201 - val_accuracy: 0.6558 - val_loss: 1.5393
Epoch 40/40
11/11 - 0s - 31ms/step - accuracy: 0.9985 - loss: 0.0166 - val_accuracy: 0.6558 - val_loss: 1.4301

Test accuracy: 0.6742770075798035
[1m 1/21[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 27ms/step[1m20/21[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 3ms/step [1m21/21[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step

Classification report:

              precision    recall  f1-score   support

        bike       0.55      0.74      0.63       101
         sit       0.93      0.74      0.83       128
  stairsdown       0.49      0.47      0.48        76
    stairsup       0.49      0.53      0.51       102
       stand       0.83      0.73      0.77       106
        walk       0.76      0.74      0.75       144

    accuracy                           0.67       657
   macro avg       0.67      0.66      0.66       657
weighted avg       0.70      0.67      0.68       657

Total processing time: 0.57 minutes
