Dask client initialized
Subsampling applied: keeping 1 every 0 rows
Rows before: 11,279,275
Rows after:  11,279,275
Retained:    100.00%
Dataset 'acc_phone' loaded with 10 partitions
Training time-series model: cnn
âœ… Time-series windows extracted: 44044
/Volumes/APFS_Bry_SSD/opt/anaconda3/envs/TFM/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                         â”ƒ Output Shape                â”ƒ         Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ conv1d (Conv1D)                      â”‚ (None, 512, 64)             â”‚           1,024 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling1d (MaxPooling1D)         â”‚ (None, 256, 64)             â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_1 (Conv1D)                    â”‚ (None, 256, 64)             â”‚          20,544 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling1d_1 (MaxPooling1D)       â”‚ (None, 128, 64)             â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten (Flatten)                    â”‚ (None, 8192)                â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                        â”‚ (None, 128)                 â”‚       1,048,704 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)                    â”‚ (None, 128)                 â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                      â”‚ (None, 6)                   â”‚             774 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 1,071,046 (4.09 MB)
 Trainable params: 1,071,046 (4.09 MB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/40
217/217 - 7s - 32ms/step - accuracy: 0.5544 - loss: 1.1454 - val_accuracy: 0.7308 - val_loss: 0.7197
Epoch 2/40
217/217 - 7s - 31ms/step - accuracy: 0.7460 - loss: 0.6761 - val_accuracy: 0.7587 - val_loss: 0.6696
Epoch 3/40
217/217 - 7s - 31ms/step - accuracy: 0.8046 - loss: 0.5467 - val_accuracy: 0.8365 - val_loss: 0.4908
Epoch 4/40
217/217 - 7s - 31ms/step - accuracy: 0.8414 - loss: 0.4523 - val_accuracy: 0.8446 - val_loss: 0.4472
Epoch 5/40
217/217 - 7s - 31ms/step - accuracy: 0.8661 - loss: 0.3855 - val_accuracy: 0.8508 - val_loss: 0.4371
Epoch 6/40
217/217 - 6s - 29ms/step - accuracy: 0.8869 - loss: 0.3244 - val_accuracy: 0.8443 - val_loss: 0.4466
Epoch 7/40
217/217 - 6s - 29ms/step - accuracy: 0.8986 - loss: 0.2939 - val_accuracy: 0.8686 - val_loss: 0.4041
Epoch 8/40
217/217 - 6s - 29ms/step - accuracy: 0.9134 - loss: 0.2480 - val_accuracy: 0.8696 - val_loss: 0.4238
Epoch 9/40
217/217 - 7s - 32ms/step - accuracy: 0.9231 - loss: 0.2208 - val_accuracy: 0.8741 - val_loss: 0.4103
Epoch 10/40
217/217 - 7s - 30ms/step - accuracy: 0.9345 - loss: 0.1884 - val_accuracy: 0.8849 - val_loss: 0.3875
Epoch 11/40
217/217 - 7s - 32ms/step - accuracy: 0.9449 - loss: 0.1606 - val_accuracy: 0.8741 - val_loss: 0.4087
Epoch 12/40
217/217 - 7s - 30ms/step - accuracy: 0.9493 - loss: 0.1459 - val_accuracy: 0.8777 - val_loss: 0.4178
Epoch 13/40
217/217 - 6s - 30ms/step - accuracy: 0.9561 - loss: 0.1268 - val_accuracy: 0.8777 - val_loss: 0.4512
Epoch 14/40
217/217 - 7s - 30ms/step - accuracy: 0.9559 - loss: 0.1295 - val_accuracy: 0.8761 - val_loss: 0.4130
Epoch 15/40
217/217 - 6s - 28ms/step - accuracy: 0.9588 - loss: 0.1181 - val_accuracy: 0.8664 - val_loss: 0.5427
Epoch 16/40
217/217 - 6s - 29ms/step - accuracy: 0.9627 - loss: 0.1095 - val_accuracy: 0.8845 - val_loss: 0.4617
Epoch 17/40
217/217 - 6s - 28ms/step - accuracy: 0.9704 - loss: 0.0839 - val_accuracy: 0.8810 - val_loss: 0.5170
Epoch 18/40
217/217 - 6s - 29ms/step - accuracy: 0.9668 - loss: 0.0940 - val_accuracy: 0.8729 - val_loss: 0.5007
Epoch 19/40
217/217 - 6s - 28ms/step - accuracy: 0.9717 - loss: 0.0859 - val_accuracy: 0.8793 - val_loss: 0.4930
Epoch 20/40
217/217 - 6s - 28ms/step - accuracy: 0.9756 - loss: 0.0716 - val_accuracy: 0.8748 - val_loss: 0.5554
Epoch 21/40
217/217 - 6s - 28ms/step - accuracy: 0.9742 - loss: 0.0759 - val_accuracy: 0.8784 - val_loss: 0.5272
Epoch 22/40
217/217 - 6s - 28ms/step - accuracy: 0.9767 - loss: 0.0675 - val_accuracy: 0.8758 - val_loss: 0.5622
Epoch 23/40
217/217 - 6s - 28ms/step - accuracy: 0.9816 - loss: 0.0559 - val_accuracy: 0.8849 - val_loss: 0.5622
Epoch 24/40
217/217 - 6s - 29ms/step - accuracy: 0.9744 - loss: 0.0783 - val_accuracy: 0.8605 - val_loss: 0.6544
Epoch 25/40
217/217 - 6s - 28ms/step - accuracy: 0.9762 - loss: 0.0719 - val_accuracy: 0.8625 - val_loss: 0.6447
Epoch 26/40
217/217 - 6s - 28ms/step - accuracy: 0.9804 - loss: 0.0615 - val_accuracy: 0.8858 - val_loss: 0.5766
Epoch 27/40
217/217 - 6s - 28ms/step - accuracy: 0.9805 - loss: 0.0605 - val_accuracy: 0.8800 - val_loss: 0.6239
Epoch 28/40
217/217 - 6s - 28ms/step - accuracy: 0.9795 - loss: 0.0604 - val_accuracy: 0.8819 - val_loss: 0.5977
Epoch 29/40
217/217 - 6s - 28ms/step - accuracy: 0.9817 - loss: 0.0555 - val_accuracy: 0.8826 - val_loss: 0.6125
Epoch 30/40
217/217 - 6s - 28ms/step - accuracy: 0.9828 - loss: 0.0518 - val_accuracy: 0.8858 - val_loss: 0.6553
Epoch 31/40
217/217 - 6s - 28ms/step - accuracy: 0.9807 - loss: 0.0595 - val_accuracy: 0.8839 - val_loss: 0.6470
Epoch 32/40
217/217 - 6s - 28ms/step - accuracy: 0.9829 - loss: 0.0496 - val_accuracy: 0.8771 - val_loss: 0.7072
Epoch 33/40
217/217 - 6s - 28ms/step - accuracy: 0.9833 - loss: 0.0488 - val_accuracy: 0.8784 - val_loss: 0.6643
Epoch 34/40
217/217 - 6s - 29ms/step - accuracy: 0.9824 - loss: 0.0520 - val_accuracy: 0.8797 - val_loss: 0.7038
Epoch 35/40
217/217 - 6s - 28ms/step - accuracy: 0.9874 - loss: 0.0390 - val_accuracy: 0.8732 - val_loss: 0.8069
Epoch 36/40
217/217 - 6s - 28ms/step - accuracy: 0.9848 - loss: 0.0447 - val_accuracy: 0.8758 - val_loss: 0.7151
Epoch 37/40
217/217 - 6s - 28ms/step - accuracy: 0.9804 - loss: 0.0565 - val_accuracy: 0.8793 - val_loss: 0.7400
Epoch 38/40
217/217 - 6s - 29ms/step - accuracy: 0.9858 - loss: 0.0412 - val_accuracy: 0.8845 - val_loss: 0.7263
Epoch 39/40
217/217 - 6s - 29ms/step - accuracy: 0.9862 - loss: 0.0409 - val_accuracy: 0.8745 - val_loss: 0.7455
Epoch 40/40
217/217 - 6s - 29ms/step - accuracy: 0.9860 - loss: 0.0427 - val_accuracy: 0.8813 - val_loss: 0.7496

Test accuracy: 0.872937798500061
[1m  1/413[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m11s[0m 27ms/step[1m 17/413[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step  [1m 34/413[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step[1m 52/413[0m [32mâ”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step[1m 70/413[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 3ms/step[1m 86/413[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m105/413[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m124/413[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m143/413[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m161/413[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m180/413[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m199/413[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m217/413[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m235/413[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m254/413[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m273/413[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m291/413[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m310/413[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 3ms/step[1m329/413[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 3ms/step[1m348/413[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 3ms/step[1m366/413[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 3ms/step[1m385/413[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 3ms/step[1m404/413[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 3ms/step[1m413/413[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 3ms/step

Classification report:

              precision    recall  f1-score   support

        bike       0.91      0.83      0.87      2467
         sit       0.94      0.97      0.95      2460
  stairsdown       0.83      0.75      0.79      1897
    stairsup       0.84      0.82      0.83      2015
       stand       0.91      0.88      0.90      2024
        walk       0.81      0.95      0.87      2351

    accuracy                           0.87     13214
   macro avg       0.87      0.87      0.87     13214
weighted avg       0.87      0.87      0.87     13214

Total processing time: 4.53 minutes
