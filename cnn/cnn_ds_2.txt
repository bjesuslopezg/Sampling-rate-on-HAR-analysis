Dask client initialized
Subsampling applied: keeping 1 every 2 rows
Rows before: 11,279,275
Rows after:  5,639,638
Retained:    50.00%
Dataset 'acc_phone' loaded with 10 partitions
Training time-series model: cnn
âœ… Time-series windows extracted: 22016
/Volumes/APFS_Bry_SSD/opt/anaconda3/envs/TFM/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                         â”ƒ Output Shape                â”ƒ         Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ conv1d (Conv1D)                      â”‚ (None, 512, 64)             â”‚           1,024 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling1d (MaxPooling1D)         â”‚ (None, 256, 64)             â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv1d_1 (Conv1D)                    â”‚ (None, 256, 64)             â”‚          20,544 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling1d_1 (MaxPooling1D)       â”‚ (None, 128, 64)             â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten (Flatten)                    â”‚ (None, 8192)                â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                        â”‚ (None, 128)                 â”‚       1,048,704 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)                    â”‚ (None, 128)                 â”‚               0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                      â”‚ (None, 6)                   â”‚             774 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 1,071,046 (4.09 MB)
 Trainable params: 1,071,046 (4.09 MB)
 Non-trainable params: 0 (0.00 B)
Epoch 1/40
109/109 - 3s - 31ms/step - accuracy: 0.5064 - loss: 1.3359 - val_accuracy: 0.6394 - val_loss: 0.8915
Epoch 2/40
109/109 - 3s - 30ms/step - accuracy: 0.7306 - loss: 0.7091 - val_accuracy: 0.7905 - val_loss: 0.5406
Epoch 3/40
109/109 - 3s - 28ms/step - accuracy: 0.7988 - loss: 0.5400 - val_accuracy: 0.7341 - val_loss: 0.7170
Epoch 4/40
109/109 - 3s - 28ms/step - accuracy: 0.8426 - loss: 0.4441 - val_accuracy: 0.8106 - val_loss: 0.4807
Epoch 5/40
109/109 - 3s - 29ms/step - accuracy: 0.8802 - loss: 0.3407 - val_accuracy: 0.8528 - val_loss: 0.4166
Epoch 6/40
109/109 - 3s - 29ms/step - accuracy: 0.8932 - loss: 0.2968 - val_accuracy: 0.8521 - val_loss: 0.3918
Epoch 7/40
109/109 - 3s - 29ms/step - accuracy: 0.9095 - loss: 0.2548 - val_accuracy: 0.8658 - val_loss: 0.3906
Epoch 8/40
109/109 - 3s - 29ms/step - accuracy: 0.9289 - loss: 0.2128 - val_accuracy: 0.8748 - val_loss: 0.3725
Epoch 9/40
109/109 - 3s - 29ms/step - accuracy: 0.9383 - loss: 0.1785 - val_accuracy: 0.8722 - val_loss: 0.3600
Epoch 10/40
109/109 - 3s - 29ms/step - accuracy: 0.9434 - loss: 0.1672 - val_accuracy: 0.8761 - val_loss: 0.3535
Epoch 11/40
109/109 - 3s - 29ms/step - accuracy: 0.9560 - loss: 0.1340 - val_accuracy: 0.8833 - val_loss: 0.3571
Epoch 12/40
109/109 - 3s - 28ms/step - accuracy: 0.9582 - loss: 0.1218 - val_accuracy: 0.8800 - val_loss: 0.3991
Epoch 13/40
109/109 - 3s - 29ms/step - accuracy: 0.9668 - loss: 0.0995 - val_accuracy: 0.8541 - val_loss: 0.4571
Epoch 14/40
109/109 - 3s - 30ms/step - accuracy: 0.9711 - loss: 0.0891 - val_accuracy: 0.8748 - val_loss: 0.4364
Epoch 15/40
109/109 - 3s - 29ms/step - accuracy: 0.9723 - loss: 0.0873 - val_accuracy: 0.8632 - val_loss: 0.4704
Epoch 16/40
109/109 - 3s - 30ms/step - accuracy: 0.9750 - loss: 0.0779 - val_accuracy: 0.8794 - val_loss: 0.4382
Epoch 17/40
109/109 - 3s - 30ms/step - accuracy: 0.9758 - loss: 0.0738 - val_accuracy: 0.8742 - val_loss: 0.4925
Epoch 18/40
109/109 - 3s - 29ms/step - accuracy: 0.9769 - loss: 0.0696 - val_accuracy: 0.8813 - val_loss: 0.4240
Epoch 19/40
109/109 - 3s - 29ms/step - accuracy: 0.9840 - loss: 0.0535 - val_accuracy: 0.8800 - val_loss: 0.4596
Epoch 20/40
109/109 - 3s - 29ms/step - accuracy: 0.9802 - loss: 0.0638 - val_accuracy: 0.8774 - val_loss: 0.5305
Epoch 21/40
109/109 - 3s - 29ms/step - accuracy: 0.9734 - loss: 0.0788 - val_accuracy: 0.8800 - val_loss: 0.4425
Epoch 22/40
109/109 - 3s - 29ms/step - accuracy: 0.9835 - loss: 0.0533 - val_accuracy: 0.8703 - val_loss: 0.5076
Epoch 23/40
109/109 - 3s - 29ms/step - accuracy: 0.9781 - loss: 0.0654 - val_accuracy: 0.8813 - val_loss: 0.4955
Epoch 24/40
109/109 - 3s - 29ms/step - accuracy: 0.9828 - loss: 0.0555 - val_accuracy: 0.8813 - val_loss: 0.4906
Epoch 25/40
109/109 - 3s - 29ms/step - accuracy: 0.9807 - loss: 0.0590 - val_accuracy: 0.8885 - val_loss: 0.4691
Epoch 26/40
109/109 - 3s - 29ms/step - accuracy: 0.9873 - loss: 0.0457 - val_accuracy: 0.8684 - val_loss: 0.5754
Epoch 27/40
109/109 - 3s - 29ms/step - accuracy: 0.9897 - loss: 0.0339 - val_accuracy: 0.8904 - val_loss: 0.4892
Epoch 28/40
109/109 - 3s - 29ms/step - accuracy: 0.9859 - loss: 0.0439 - val_accuracy: 0.8865 - val_loss: 0.4973
Epoch 29/40
109/109 - 3s - 29ms/step - accuracy: 0.9866 - loss: 0.0453 - val_accuracy: 0.8878 - val_loss: 0.4990
Epoch 30/40
109/109 - 3s - 29ms/step - accuracy: 0.9850 - loss: 0.0490 - val_accuracy: 0.8748 - val_loss: 0.5932
Epoch 31/40
109/109 - 3s - 29ms/step - accuracy: 0.9798 - loss: 0.0589 - val_accuracy: 0.8826 - val_loss: 0.5149
Epoch 32/40
109/109 - 3s - 29ms/step - accuracy: 0.9849 - loss: 0.0440 - val_accuracy: 0.8846 - val_loss: 0.5691
Epoch 33/40
109/109 - 3s - 29ms/step - accuracy: 0.9863 - loss: 0.0420 - val_accuracy: 0.8664 - val_loss: 0.6491
Epoch 34/40
109/109 - 3s - 29ms/step - accuracy: 0.9868 - loss: 0.0438 - val_accuracy: 0.8878 - val_loss: 0.4818
Epoch 35/40
109/109 - 3s - 29ms/step - accuracy: 0.9898 - loss: 0.0347 - val_accuracy: 0.8606 - val_loss: 0.7114
Epoch 36/40
109/109 - 3s - 30ms/step - accuracy: 0.9885 - loss: 0.0351 - val_accuracy: 0.8774 - val_loss: 0.6431
Epoch 37/40
109/109 - 3s - 29ms/step - accuracy: 0.9908 - loss: 0.0294 - val_accuracy: 0.8839 - val_loss: 0.5915
Epoch 38/40
109/109 - 3s - 29ms/step - accuracy: 0.9911 - loss: 0.0287 - val_accuracy: 0.8826 - val_loss: 0.6011
Epoch 39/40
109/109 - 3s - 29ms/step - accuracy: 0.9924 - loss: 0.0277 - val_accuracy: 0.8878 - val_loss: 0.5690
Epoch 40/40
109/109 - 3s - 29ms/step - accuracy: 0.9934 - loss: 0.0202 - val_accuracy: 0.8878 - val_loss: 0.5633

Test accuracy: 0.8819076418876648
[1m  1/207[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m5s[0m 27ms/step[1m 17/207[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step [1m 33/207[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m 48/207[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m 64/207[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m 79/207[0m [32mâ”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m 96/207[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m113/207[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m130/207[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m147/207[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 3ms/step[1m163/207[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 3ms/step[1m179/207[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”[0m [1m0s[0m 3ms/step[1m195/207[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 3ms/step[1m207/207[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 3ms/step[1m207/207[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 3ms/step

Classification report:

              precision    recall  f1-score   support

        bike       0.86      0.83      0.85      1063
         sit       0.93      0.96      0.94      1216
  stairsdown       0.84      0.85      0.84       929
    stairsup       0.86      0.83      0.85      1031
       stand       0.86      0.91      0.89      1064
        walk       0.92      0.89      0.91      1302

    accuracy                           0.88      6605
   macro avg       0.88      0.88      0.88      6605
weighted avg       0.88      0.88      0.88      6605

Total processing time: 2.49 minutes
